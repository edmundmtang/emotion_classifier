{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972b31e1-c4cb-4de0-b0fe-ab740b1fee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b128a94-06d1-4381-8b84-9fadbcf043a6",
   "metadata": {},
   "source": [
    "### Set Up CUDA Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2784050-78d1-4553-8bce-93998b96312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "SEED = 19\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27031342-a5ae-41b2-8035-38706939e4eb",
   "metadata": {},
   "source": [
    "### Set up Tokenizer and Max Input Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0259e3ca-758c-47f5-a9eb-263196529dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c3fcb1-85a7-4df5-a647-637c207f19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input(input_text: str):\n",
    "    input_ids = tokenizer.encode(input_text, add_special_tokens=True,max_length=MAX_LEN,padding=\"max_length\",truncation=True)\n",
    "    attention_mask = [float(i>0) for i in input_ids]\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cceed-4062-42c1-826c-3543382a243f",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "587c6a25-07f5-4db1-a704-25d288220fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModule(torch.nn.Module):\n",
    "    def __init__(self, N, M):\n",
    "        super(TestModule, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N,M))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.weight + input\n",
    "        return output\n",
    "\n",
    "test_model = TestModule(10,20)\n",
    "traced_test_model = torch.jit.trace(test_model, torch.rand(10,20))\n",
    "torch.jit.save(traced_test_model, \"cpp_implementation/model/traced_test_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03995043-12df-4bfe-8507-48b685198cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3234, 0.4146, 1.5300, 1.0233, 0.9296, 0.9264, 1.2571, 0.2846, 1.1305,\n",
       "         1.8966, 1.0159, 0.8344, 0.3349, 0.1053, 1.4521, 0.8973, 1.0102, 0.0964,\n",
       "         1.0318, 1.0100],\n",
       "        [0.2821, 0.9347, 0.9755, 1.0972, 0.7162, 0.7428, 1.5503, 0.7036, 0.6201,\n",
       "         1.0893, 1.8649, 1.2398, 1.3660, 1.8776, 1.0299, 0.2941, 0.5068, 1.2674,\n",
       "         0.3258, 1.6474],\n",
       "        [0.5563, 0.6325, 1.0845, 0.7499, 0.7171, 1.3896, 1.4508, 0.2293, 1.4863,\n",
       "         0.8581, 0.8256, 0.5737, 1.3381, 0.3949, 0.1705, 0.8039, 0.7444, 1.1505,\n",
       "         0.9634, 1.4007],\n",
       "        [0.6120, 1.5510, 0.9598, 0.9128, 1.0110, 1.1201, 1.5673, 0.7439, 1.5159,\n",
       "         1.6113, 0.3120, 0.8220, 1.0192, 1.3265, 0.4369, 1.4185, 1.0756, 0.9926,\n",
       "         0.9987, 0.9466],\n",
       "        [0.4969, 0.9322, 1.4344, 1.1974, 1.4854, 1.2386, 0.7164, 0.9035, 1.4181,\n",
       "         1.4654, 0.1916, 0.7707, 0.6331, 1.4596, 0.1925, 1.8217, 0.2660, 1.6215,\n",
       "         1.5253, 1.4100],\n",
       "        [1.0160, 1.4793, 0.7380, 1.0065, 1.3689, 1.1495, 0.9379, 0.8161, 1.1130,\n",
       "         1.4018, 0.7273, 0.8989, 1.3071, 0.3950, 0.5650, 0.7981, 1.3236, 0.9417,\n",
       "         0.4236, 1.5157],\n",
       "        [1.4327, 1.2514, 0.9735, 1.0345, 0.9015, 1.4918, 0.7391, 0.6371, 1.2948,\n",
       "         0.8114, 1.5664, 1.5422, 1.0463, 1.5241, 1.3084, 0.6217, 0.2591, 1.0158,\n",
       "         1.3304, 0.7878],\n",
       "        [1.4764, 0.8388, 1.1602, 1.1599, 0.5033, 1.0555, 1.1596, 0.1115, 1.2930,\n",
       "         0.7963, 1.3655, 0.9202, 1.2083, 1.2073, 1.5499, 1.5140, 0.4539, 1.2193,\n",
       "         0.9952, 1.6120],\n",
       "        [0.8515, 1.6539, 1.7079, 1.2420, 0.9725, 1.0172, 0.6551, 1.4798, 1.2741,\n",
       "         1.4622, 1.3055, 0.9437, 0.9778, 1.0708, 0.5191, 1.1327, 0.9024, 1.2629,\n",
       "         1.1782, 1.5453],\n",
       "        [1.2252, 1.1505, 1.3336, 0.0405, 0.0870, 0.4654, 0.8725, 1.4333, 0.7508,\n",
       "         0.8731, 1.5002, 1.0193, 1.5472, 0.6319, 1.6440, 0.0669, 1.1941, 0.8249,\n",
       "         0.1613, 0.1728]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_test_model(torch.rand(10,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e435e-9348-4eb7-ac86-456f23131499",
   "metadata": {},
   "source": [
    "### TorchScript Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a6d55e1-44a6-4c4e-af01-4b7452e318cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing input text and creating attention mask\n",
    "text = \"I am feeling awfully sad right now.\"\n",
    "input_ids, attention_mask = prep_input(text)\n",
    "\n",
    "# Creating a dummy input\n",
    "input_tensor = torch.tensor([input_ids])\n",
    "attention_tensor = torch.tensor([attention_mask])\n",
    "dummy_input = [input_tensor, attention_tensor]\n",
    "\n",
    "# Initializing the model with torchscript flag\n",
    "model = BertForSequenceClassification.from_pretrained(\"model/\", torchscript=True)\n",
    "model.eval()\n",
    "\n",
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model, [input_tensor, attention_tensor])\n",
    "torch.jit.save(traced_model, \"cpp_implementation/model/traced_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1c121c-5fbd-421f-a7ce-e3906c483385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.size())\n",
    "print(attention_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c80de0-a8b8-4e3c-a778-f51994978f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.9769, -1.6921, -1.8883, -0.9651,  7.1175, -1.5798]],\n",
       "        grad_fn=<AddmmBackward0>),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model(input_tensor, attention_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49039a7f-6397-48b4-b229-886dfe2a080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([101, 1045, 2064, 1005, 1056, 2022, 6517, 2055, 2008, 1012, 1031, 14477, 20961, 3468, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"i can't be sad about that. [ unaffable\"\n",
    "print(prep_input(text_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
